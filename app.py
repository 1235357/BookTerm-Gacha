"""
BookTerm Gacha - Main Application Entry Point
==============================================

A specialized term extraction tool for books (EPUB/TXT/MD) that uses
BERT-based NER and LLM semantic analysis to generate translation glossaries.

Main Workflow:
    1. Read input files (EPUB, TXT, MD, etc.) from the input folder
    2. Extract named entities using BERT NER model
    3. Analyze terms with LLM to determine categories and translations
    4. Generate output files (JSON, MD, XLSX) for use in translation tools

Key Features:
    - Multi-language support: Chinese, Japanese, Korean, English
    - GPU acceleration for NER (CUDA)
    - Configurable LLM backends (OpenAI-compatible APIs)
    - Quality checks for kana residue and similarity issues
    - Traditional/Simplified Chinese output options

Configuration:
    All settings are loaded from config.json in the application directory.
    See README.md for detailed configuration options.

Usage:
    python app.py

Based on KeywordGacha v0.13.1 by neavo
https://github.com/neavo/KeywordGacha
"""

import os
import sys
import copy
import json
import asyncio
import subprocess
import re
from types import SimpleNamespace
import argparse
import threading
import time

# ============== Windows æ§åˆ¶å° UTF-8 ç¼–ç è®¾ç½®ï¼ˆå¿…é¡»åœ¨æœ€å¼€å§‹ï¼‰ ==============
if sys.platform == 'win32':
    try:
        import ctypes
        # è®¾ç½®æ§åˆ¶å°è¾“å‡ºä»£ç é¡µä¸º UTF-8
        ctypes.windll.kernel32.SetConsoleOutputCP(65001)
        ctypes.windll.kernel32.SetConsoleCP(65001)
    except:
        pass
    
    # è®¾ç½®æ ‡å‡†è¾“å‡ºç¼–ç 
    if hasattr(sys.stdout, 'reconfigure'):
        try:
            sys.stdout.reconfigure(encoding='utf-8', errors='replace')
            sys.stderr.reconfigure(encoding='utf-8', errors='replace')
        except:
            pass


def run_environment_check() -> bool:
    """
    è¿è¡Œç¯å¢ƒæ£€æŸ¥å’Œè‡ªåŠ¨ä¿®å¤
    
    Returns:
        True å¦‚æœç¯å¢ƒå°±ç»ªï¼ŒFalse å¦‚æœå¤±è´¥
    """
    try:
        from module.EnvChecker import check_environment
        return check_environment(auto_repair=True)
    except ImportError:
        # Rich æœªå®‰è£…ï¼Œå…ˆå®‰è£…åŸºç¡€åŒ…
        print("=" * 60)
        print("  é¦–æ¬¡è¿è¡Œï¼Œæ­£åœ¨åˆå§‹åŒ–ç¯å¢ƒ...")
        print("=" * 60)
        
        mirrors = [
            "https://pypi.tuna.tsinghua.edu.cn/simple",
            "https://mirrors.aliyun.com/pypi/simple",
        ]
        
        for mirror in mirrors:
            try:
                result = subprocess.run(
                    [sys.executable, "-m", "pip", "install", "-i", mirror, 
                     "--trusted-host", mirror.split("//")[1].split("/")[0],
                     "rich", "loguru"],
                    capture_output=True,
                    text=True,
                    timeout=120
                )
                if result.returncode == 0:
                    print(f"  âœ“ åŸºç¡€åŒ…å®‰è£…æˆåŠŸ")
                    break
            except Exception:
                continue
        
        # é‡æ–°å°è¯•
        try:
            from module.EnvChecker import check_environment
            return check_environment(auto_repair=True)
        except Exception as e:
            print(f"\nâŒ ç¯å¢ƒåˆå§‹åŒ–å¤±è´¥: {e}")
            print("   è¯·æ‰‹åŠ¨è¿è¡Œ: pip install -r requirements.txt")
            return False


# ============== ç¯å¢ƒæ£€æŸ¥ï¼ˆå¿…é¡»åœ¨å¯¼å…¥å…¶ä»–æ¨¡å—ä¹‹å‰ï¼‰ ==============
if __name__ == "__main__":
    if not run_environment_check():
        print("\nâŒ ç¯å¢ƒæ£€æµ‹å¤±è´¥ï¼Œè¯·æ‰‹åŠ¨å®‰è£…ä¾èµ–åé‡è¯•")
        print("   å‚è€ƒå‘½ä»¤: pip install -r requirements.txt")
        os.system("pause")
        sys.exit(1)


# ============== ç¯å¢ƒæ£€æŸ¥é€šè¿‡åï¼Œå¯¼å…¥æ‰€æœ‰ä¾èµ– ==============
from rich import box
from rich.table import Table
from rich.prompt import Prompt
from rich.traceback import install

from model.LLM import LLM
from model.NER import NER
from model.Word import Word
from module.LogHelper import LogHelper
from module.ProgressHelper import ProgressHelper
from module.TestHelper import TestHelper
from module.FileManager import FileManager
from module.Text.TextHelper import TextHelper


def _resolve_platform_api_keys(platform: dict) -> list[str]:
    keys: list[str] = []

    env_name = platform.get("api_key_env", "") if isinstance(platform, dict) else ""
    if isinstance(env_name, str) and env_name.strip():
        env_val = os.environ.get(env_name.strip(), "") or ""
        for part in re.split(r"[,\n;]+", env_val):
            m = re.search(r"(nvapi-[A-Za-z0-9_\-]{20,})", part.strip())
            if m:
                keys.append(m.group(1))

    file_path = platform.get("api_key_file", "") if isinstance(platform, dict) else ""
    if isinstance(file_path, str) and file_path.strip():
        abs_path = file_path.strip()
        if not os.path.isabs(abs_path):
            abs_path = os.path.join(os.getcwd(), abs_path)
        try:
            with open(abs_path, "r", encoding="utf-8-sig") as reader:
                for line in reader.read().splitlines():
                    m = re.search(r"(nvapi-[A-Za-z0-9_\-]{20,})", line.strip())
                    if m:
                        keys.append(m.group(1))
        except Exception:
            pass

    api_key_value = platform.get("api_key", []) if isinstance(platform, dict) else []
    if isinstance(api_key_value, str):
        m = re.search(r"(nvapi-[A-Za-z0-9_\-]{20,})", api_key_value.strip())
        if m:
            keys.append(m.group(1))
    elif isinstance(api_key_value, list):
        for item in api_key_value:
            if not isinstance(item, str):
                continue
            m = re.search(r"(nvapi-[A-Za-z0-9_\-]{20,})", item.strip())
            if m:
                keys.append(m.group(1))

    deduped: list[str] = []
    seen: set[str] = set()
    for k in keys:
        if k not in seen:
            seen.add(k)
            deduped.append(k)
    return deduped


# ============== é…ç½®å¸¸é‡ï¼ˆé»˜è®¤å€¼ï¼Œä¼šè¢« config.json è¦†ç›–ï¼‰ ==============
SCORE_THRESHOLD = 0.60          # ç½®ä¿¡åº¦é˜ˆå€¼
MAX_DISPLAY_LENGTH = 32         # æœ¯è¯­æœ€å¤§æ˜¾ç¤ºé•¿åº¦

# åˆå¹¶è¯è¯­
def merge_words(words: list[Word]) -> list[Word]:
    words_unique = {}
    for word in words:
        words_unique.setdefault(word.surface, []).append(word)

    words_merged = []
    for v in words_unique.values():
        word = v[0]
        word.score = min(0.9999, max(w.score for w in v))
        words_merged.append(word)

    return sorted(words_merged, key = lambda x: x.count, reverse = True)


# è¿‡æ»¤è¶…é•¿æœ¯è¯­ï¼ˆå€Ÿé‰´è‡ª V0.20.2ï¼‰
def filter_by_display_length(words: list[Word], max_length: int = MAX_DISPLAY_LENGTH) -> list[Word]:
    """è¿‡æ»¤æ˜¾ç¤ºé•¿åº¦è¶…è¿‡é˜ˆå€¼çš„æœ¯è¯­"""
    filtered = []
    for word in words:
        display_length = TextHelper.get_display_lenght(word.surface)
        if display_length <= max_length:
            filtered.append(word)
        else:
            LogHelper.debug(f"[é•¿åº¦è¿‡æ»¤] è¿‡æ»¤è¶…é•¿æœ¯è¯­: {word.surface} (é•¿åº¦: {display_length})")
    return filtered

# æœç´¢å‚è€ƒæ–‡æœ¬ï¼Œå¹¶æŒ‰å‡ºç°æ¬¡æ•°æ’åº
def search_for_context(words: list[Word], input_lines: list[str]) -> list[Word]:
    # å¤åˆ¶ä¸€ä»½ï¼Œé¿å…åç»­çš„ä¿®æ”¹å½±å“åŸå§‹æ•°æ®
    input_lines_ex = copy.copy(input_lines)

    # æŒ‰å®ä½“è¯è¯­çš„é•¿åº¦é™åºæ’åº
    words = sorted(words, key = lambda v: len(v.surface), reverse = True)

    LogHelper.print("")
    with ProgressHelper.get_progress() as progress:
        pid = progress.add_task("æœç´¢å‚è€ƒæ–‡æœ¬", total = len(words))

        # æœç´¢å‚è€ƒæ–‡æœ¬
        for word in words:
            # æ‰¾å‡ºåŒ¹é…çš„è¡Œ
            index = {i for i, line in enumerate(input_lines_ex) if word.surface in line}

            # è·å–åŒ¹é…çš„å‚è€ƒæ–‡æœ¬ï¼Œå»é‡ï¼Œå¹¶æŒ‰é•¿åº¦é™åºæ’åº
            word.context = {line for i, line in enumerate(input_lines) if i in index}
            word.context = sorted(list(word.context), key = lambda v: len(v), reverse = True)
            word.count = len(word.context)
            word.group = "æœªçŸ¥ç±»å‹"

            # æ©ç›–å·²å‘½ä¸­çš„å®ä½“è¯è¯­æ–‡æœ¬ï¼Œé¿å…å…¶å­ä¸²é”™è¯¯çš„ä¸çˆ¶ä¸²åŒ¹é…
            input_lines_ex = [
                line.replace(word.surface, len(word.surface) * "#")  if i in index else line
                for i, line in enumerate(input_lines_ex)
            ]

            # æ›´æ–°è¿›åº¦æ¡
            progress.update(pid, advance = 1)
    LogHelper.print("")

    # æŒ‰å‡ºç°æ¬¡æ•°é™åºæ’åº
    return sorted(words, key = lambda x: x.count, reverse = True)

# æŒ‰ç½®ä¿¡åº¦è¿‡æ»¤è¯è¯­
def filter_words_by_score(words: list[Word], threshold: float) -> list[Word]:
    return [word for word in words if word.score >= threshold]

# æŒ‰å‡ºç°æ¬¡æ•°è¿‡æ»¤è¯è¯­
def filter_words_by_count(words: list[Word], threshold: float) -> list[Word]:
    return [word for word in words if word.count >= max(1, threshold)]

# è·å–æŒ‡å®šç±»å‹çš„è¯
def get_words_by_type(words: list[Word], group: str) -> list[Word]:
    return [word for word in words if word.group == group]

# ç§»é™¤æŒ‡å®šç±»å‹çš„è¯
def remove_words_by_type(words: list[Word], group: str) -> list[Word]:
    return [word for word in words if word.group != group]

# å¼€å§‹å¤„ç†æ–‡æœ¬
async def process_text(llm: LLM, ner: NER, file_manager: FileManager, config: SimpleNamespace, language: int) -> None:
    # åˆå§‹åŒ–
    words = []

    # è¯»å–è¾“å…¥æ–‡ä»¶
    input_lines, names, nicknames = file_manager.read_lines_from_input_file(language)

    # æŸ¥æ‰¾å®ä½“è¯è¯­
    LogHelper.info("å³å°†å¼€å§‹æ‰§è¡Œ [æŸ¥æ‰¾å®ä½“è¯è¯­] ...")
    words, fake_name_mapping = ner.search_for_entity(input_lines, names, nicknames, language)

    # åˆå¹¶ç›¸åŒè¯æ¡
    words = merge_words(words)

    # è°ƒè¯•åŠŸèƒ½
    TestHelper.check_score_threshold(words, "log_score_threshold.log")

    # ç½®ä¿¡åº¦é˜ˆå€¼è¿‡æ»¤
    LogHelper.info(f"å³å°†å¼€å§‹æ‰§è¡Œ [ç½®ä¿¡åº¦é˜ˆå€¼]ï¼Œå½“å‰ç½®ä¿¡åº¦çš„é˜ˆå€¼ä¸º {SCORE_THRESHOLD:.4f} ...")
    words = filter_words_by_score(words, SCORE_THRESHOLD)
    LogHelper.info("[ç½®ä¿¡åº¦é˜ˆå€¼] å·²å®Œæˆ ...")

    # æœç´¢å‚è€ƒæ–‡æœ¬
    LogHelper.info("å³å°†å¼€å§‹æ‰§è¡Œ [æœç´¢å‚è€ƒæ–‡æœ¬] ...")
    words = search_for_context(words, input_lines)

    # å‡ºç°æ¬¡æ•°é˜ˆå€¼è¿‡æ»¤
    LogHelper.info(f"å³å°†å¼€å§‹æ‰§è¡Œ [å‡ºç°æ¬¡æ•°é˜ˆå€¼]ï¼Œå½“å‰å‡ºç°æ¬¡æ•°çš„é˜ˆå€¼ä¸º {config.count_threshold} ...")
    words = filter_words_by_count(words, config.count_threshold)
    LogHelper.info("[å‡ºç°æ¬¡æ•°é˜ˆå€¼] å·²å®Œæˆ ...")

    # é•¿åº¦è¿‡æ»¤ï¼ˆè¿‡æ»¤æ˜¾ç¤ºé•¿åº¦è¶…è¿‡32çš„è¶…é•¿æœ¯è¯­ï¼Œå€Ÿé‰´ V0.20.2ï¼‰
    LogHelper.info(f"å³å°†å¼€å§‹æ‰§è¡Œ [é•¿åº¦è¿‡æ»¤]ï¼Œè¿‡æ»¤æ˜¾ç¤ºé•¿åº¦è¶…è¿‡ {MAX_DISPLAY_LENGTH} çš„æœ¯è¯­ ...")
    original_count = len(words)
    words = filter_by_display_length(words, MAX_DISPLAY_LENGTH)
    filtered_count = original_count - len(words)
    if filtered_count > 0:
        LogHelper.info(f"[é•¿åº¦è¿‡æ»¤] å·²è¿‡æ»¤ {filtered_count} ä¸ªè¶…é•¿æœ¯è¯­ ...")
    LogHelper.info("[é•¿åº¦è¿‡æ»¤] å·²å®Œæˆ ...")

    # è®¾ç½® LLM å¯¹è±¡
    llm.set_language(language)
    llm.set_request_limiter()

    # ============== æ–°å·¥ä½œæµç¨‹ï¼šæ•´åˆä¸ºå•ä¸€ä»»åŠ¡æµï¼ˆç¿»è¯‘â†’æ ¡å¯¹å®¡æŸ¥ï¼‰=============
    LogHelper.info("å³å°†å¼€å§‹æ‰§è¡Œ [ç¿»è¯‘+æ ¡å¯¹]ï¼ˆåŒä¸€æ‰¹ä»»åŠ¡å¹¶è¡Œæ¨è¿›ï¼Œé¿å…é˜¶æ®µåˆ‡å‰²ï¼‰...")
    words = await llm.translate_and_surface_analysis_batch(words, fake_name_mapping)
    words = remove_words_by_type(words, "")

    # æ­¥éª¤3ï¼šé—®é¢˜ä¿®å¤ï¼ˆç¬¬ä¸‰é˜¶æ®µï¼šæ£€æµ‹å¹¶ä¿®å¤é—®é¢˜è¯æ¡ï¼‰
    LogHelper.info("")
    LogHelper.info("å³å°†å¼€å§‹æ‰§è¡Œ [é—®é¢˜ä¿®å¤]ï¼ˆç¬¬ä¸‰é˜¶æ®µï¼šæ£€æµ‹é—®é¢˜è¯æ¡ï¼Œè‡ªåŠ¨ä¿®å¤ï¼‰...")
    words = await llm.fix_translation_batch(words)

    # è°ƒè¯•åŠŸèƒ½
    TestHelper.save_surface_analysis_log(words, "log_surface_analysis.log")
    TestHelper.check_result_duplication(words, "log_result_duplication.log")
    TestHelper.save_context_translate_log(words, "log_context_translate.log")

    # è¿˜åŸä¼ªå
    for word in words:
        for k, v in fake_name_mapping.items():
            word.context_summary = word.context_summary.replace(v, k)
            word.context = [line.replace(v, k) for line in word.context]
            word.context_translation = [line.replace(v, k) for line in word.context_translation]

    # å°†ç»“æœå†™å…¥æ–‡ä»¶
    LogHelper.info("")
    file_manager.write_result_to_file(words, language)

    # æ‰§è¡Œç»“æœæ£€æŸ¥
    LogHelper.info("")
    from module.ResultChecker import ResultChecker
    checker = ResultChecker(words, language)
    checker.check_all()

    # ç­‰å¾…ç”¨æˆ·é€€å‡º
    LogHelper.info("")
    LogHelper.info("å·¥ä½œæµç¨‹å·²ç»“æŸ ... è¯·æ£€æŸ¥ç”Ÿæˆçš„æ•°æ®æ–‡ä»¶ ...")
    LogHelper.info("")
    LogHelper.info("")
    os.system("pause")

# æ¥å£æµ‹è¯•
async def test_api(llm: LLM) -> None:
    # è®¾ç½®è¯·æ±‚é™åˆ¶å™¨
    await llm.set_request_limiter()

    # ç­‰å¾…æ¥å£æµ‹è¯•ç»“æœ
    if await llm.api_test():
        LogHelper.print("")
        LogHelper.info("æ¥å£æµ‹è¯• [green]æ‰§è¡ŒæˆåŠŸ[/] ...")
    else:
        LogHelper.print("")
        LogHelper.warning("æ¥å£æµ‹è¯• [red]æ‰§è¡Œå¤±è´¥[/], è¯·æ£€æŸ¥é…ç½®æ–‡ä»¶ ...")

    LogHelper.print("")
    os.system("pause")
    os.system("cls")

# æ‰“å°åº”ç”¨ä¿¡æ¯
def print_app_info(config: SimpleNamespace, version: str) -> None:
    LogHelper.print()
    LogHelper.print()
    LogHelper.rule(f"ğŸ“š BookTerm Gacha {version}", style = "light_goldenrod2")
    LogHelper.rule("[blue]An LLM-Powered Agent for Book Terminology Extraction", style = "light_goldenrod2")
    LogHelper.rule("ä¸“ä¸ºä¹¦ç±ï¼ˆEPUB/TXT/MDï¼‰ä¼˜åŒ–çš„ LLM æœ¯è¯­è¡¨ç”Ÿæˆå·¥å…·", style = "light_goldenrod2")
    LogHelper.print()

    table = Table(
        box = box.ASCII2,
        expand = True,
        highlight = True,
        show_lines = True,
        show_header = False,
        border_style = "light_goldenrod2",
    )
    table.add_column("", style = "white", ratio = 2, overflow = "fold")
    table.add_column("", style = "white", ratio = 5, overflow = "fold")

    rows = []
    
    # æ˜¾ç¤ºå¹³å°åç§°ï¼ˆå¦‚æœæœ‰ï¼‰
    platform_name = getattr(config, 'platform_name', None)
    if platform_name:
        rows.append(("å½“å‰å¹³å°", f"[bold cyan]{platform_name}[/]"))
    
    rows.append(("æ¨¡å‹åç§°", str(config.model_name)))
    
    # API Key æ˜¾ç¤ºä¼˜åŒ–ï¼ˆæ”¯æŒå¤š Keyï¼‰
    api_key = config.api_key
    if isinstance(api_key, list):
        if len(api_key) > 1:
            rows.append(("API Key", f"[green]{len(api_key)} ä¸ª Key (è½®è¯¢æ¨¡å¼)[/]"))
        elif len(api_key) == 1:
            rows.append(("API Key", f"{api_key[0][:20]}..."))
        else:
            rows.append(("API Key", "[red]æœªé…ç½®[/]"))
    else:
        rows.append(("API Key", str(api_key)[:40] + "..." if len(str(api_key)) > 40 else str(api_key)))
    
    rows.append(("æ¥å£åœ°å€", str(config.base_url)))
    rows.append(("ç½‘ç»œè¯·æ±‚è¶…æ—¶æ—¶é—´", f"{config.request_timeout} ç§’"))
    rows.append(("ç½‘ç»œè¯·æ±‚é¢‘ç‡é˜ˆå€¼", f"{config.request_frequency_threshold} æ¬¡/ç§’"))
    rows.append(("æœ€å¤§å¹¶å‘è¯·æ±‚æ•°", f"{getattr(config, 'max_concurrent_requests', 5)} ä¸ª"))
    rows.append(("å‚è€ƒæ–‡æœ¬ç¿»è¯‘æ¨¡å¼", "æ–°æµç¨‹ï¼šå…ˆç¿»è¯‘ååˆ†æï¼ˆå¼ºåˆ¶å¯ç”¨ï¼‰"))

    for row in rows:
        table.add_row(*row)
    LogHelper.print(table)

    LogHelper.print()
    LogHelper.print("è¯·ç¼–è¾‘ [green]config.json[/] æ–‡ä»¶æ¥ä¿®æ”¹åº”ç”¨è®¾ç½® ...")
    LogHelper.print("æç¤º: ä¿®æ”¹ [cyan]activate_platform[/] å­—æ®µæ¥åˆ‡æ¢ä¸åŒçš„ API å¹³å°")
    LogHelper.print()

# æ‰“å°èœå•
async def print_menu_main() -> int:
    LogHelper.print("è¯·é€‰æ‹©åŠŸèƒ½ï¼š")
    LogHelper.print("")
    LogHelper.print("\t--> 1. å¼€å§‹å¤„ç† [green]ä¸­æ–‡æ–‡æœ¬[/]")
    LogHelper.print("\t--> 2. å¼€å§‹å¤„ç† [green]è‹±æ–‡æ–‡æœ¬[/]")
    LogHelper.print("\t--> 3. å¼€å§‹å¤„ç† [green]æ—¥æ–‡æ–‡æœ¬[/]")
    LogHelper.print("\t--> 4. å¼€å§‹å¤„ç† [green]éŸ©æ–‡æ–‡æœ¬[/]")
    LogHelper.print("\t--> 5. å¼€å§‹æ‰§è¡Œ [green]æ¥å£æµ‹è¯•[/]")
    LogHelper.print("\t--> 6. æ‰“å¼€ [green]é…ç½®é¢æ¿[/]ï¼ˆäº¤äº’å¼ç¼–è¾‘ï¼‰")
    LogHelper.print("\t--> 7. æŸ¥çœ‹ [green]è¿è¡ŒçŠ¶æ€é¢æ¿[/]")
    LogHelper.print("")
    choice_text = await asyncio.to_thread(
        Prompt.ask,
        "è¯·è¾“å…¥é€‰é¡¹å‰çš„ [green]æ•°å­—åºå·[/] æ¥ä½¿ç”¨å¯¹åº”çš„åŠŸèƒ½ï¼Œé»˜è®¤ä¸º [green][3][/] ",
        choices=["1", "2", "3", "4", "5", "6", "7"],
        default="3",
        show_choices=False,
        show_default=False,
    )
    choice = int(choice_text)
    LogHelper.print("")

    return choice

# ä¸»å‡½æ•°
async def begin(llm: LLM, ner: NER, file_manager: FileManager, config: SimpleNamespace, version: str) -> None:
    choice = -1
    while choice not in (1, 2, 3, 4):
        print_app_info(config, version)

        choice = await print_menu_main()
        if choice == 1:
            await process_text(llm, ner, file_manager, config, NER.Language.ZH)
        elif choice == 2:
            await process_text(llm, ner, file_manager, config, NER.Language.EN)
        elif choice == 3:
            await process_text(llm, ner, file_manager, config, NER.Language.JA)
        elif choice == 4:
            await process_text(llm, ner, file_manager, config, NER.Language.KO)
        elif choice == 5:
            await test_api(llm)
        elif choice == 6:
            from module.ConsolePanels import interactive_config_edit
            changed = await asyncio.to_thread(interactive_config_edit)
            if changed:
                _hot_reload_config(llm, config)
        elif choice == 7:
            from module.ConsolePanels import show_status_live
            await asyncio.to_thread(show_status_live, llm)


def _start_runtime_status_writer(llm: LLM):
    try:
        from module.RuntimeStatusStore import RuntimeStatusWriter
        w = RuntimeStatusWriter(get_status=llm.get_runtime_status, interval_seconds=1.0)
        w.start()
        return w
    except Exception:
        return None


def _update_namespace_in_place(dst: SimpleNamespace, src: SimpleNamespace) -> None:
    dst.__dict__.clear()
    dst.__dict__.update(src.__dict__)


def _select_config_path() -> str:
    if not os.path.isfile("config_dev.json"):
        return "config.json"
    return "config_dev.json"


def _load_config_namespace() -> tuple[SimpleNamespace, str]:
    config = SimpleNamespace()
    version = ""
    raw_config = {}
    path = _select_config_path()

    try:
        with open(path, "r", encoding="utf-8-sig") as reader:
            raw_config = json.load(reader)

        if "platforms" in raw_config and "activate_platform" in raw_config:
            platforms = raw_config.get("platforms", [])
            activate_id = raw_config.get("activate_platform", 0)

            active_platform = None
            for platform in platforms:
                if platform.get("id") == activate_id:
                    active_platform = platform
                    break

            if active_platform is None and platforms:
                active_platform = platforms[0]
                LogHelper.warning(f"[é…ç½®è­¦å‘Š] æœªæ‰¾åˆ° ID={activate_id} çš„å¹³å°ï¼Œä½¿ç”¨é»˜è®¤å¹³å°: {active_platform.get('name', 'Unknown')}")

            if active_platform:
                config.api_key = _resolve_platform_api_keys(active_platform)
                config.base_url = active_platform.get("api_url", "")
                config.model_name = active_platform.get("model", "")
                config.platform_name = active_platform.get("name", "Unknown")
                config.thinking = active_platform.get("thinking", True)
                config.top_p = active_platform.get("top_p", 0.95)
                config.temperature = active_platform.get("temperature", 0.05)

            for k, v in raw_config.items():
                if k not in ("platforms", "activate_platform"):
                    if isinstance(v, list) and len(v) > 0 and not k.startswith("api"):
                        setattr(config, k, v[0])
                    elif not isinstance(v, list):
                        setattr(config, k, v)
        else:
            for k, v in raw_config.items():
                setattr(config, k, v[0] if isinstance(v, list) else v)

        with open("version.txt", "r", encoding="utf-8-sig") as reader:
            version = reader.read().strip()
    except Exception as e:
        LogHelper.error(f"é…ç½®æ–‡ä»¶è¯»å–å¤±è´¥: {e}")

    return config, version


def _apply_global_settings(config: SimpleNamespace) -> None:
    global SCORE_THRESHOLD, MAX_DISPLAY_LENGTH
    SCORE_THRESHOLD = getattr(config, "score_threshold", 0.60)
    MAX_DISPLAY_LENGTH = getattr(config, "max_display_length", 32)
    Word.set_config(
        max_context_samples=getattr(config, "max_context_samples", 10),
        tokens_per_sample=getattr(config, "tokens_per_sample", 512),
    )
    task_timeout = getattr(config, "task_timeout_threshold", 430)
    LLM.TASK_TIMEOUT_THRESHOLD = task_timeout

    try:
        from module.ErrorLogger import ErrorLogger

        ErrorLogger.configure(
            enabled=getattr(config, "error_detail_log_enable", True),
            max_chars=getattr(config, "error_detail_log_max_chars", 20000),
            log_file=getattr(config, "error_detail_log_file", "log/error_detail.log"),
        )
    except Exception:
        pass


def _hot_reload_config(llm: LLM, config_obj: SimpleNamespace) -> None:
    new_config, _ = _load_config_namespace()
    old_keys = list(getattr(llm, "api_keys", []) or [])
    old_url = getattr(llm, "base_url", "")
    old_model = getattr(llm, "model_name", "")
    new_keys = list(getattr(new_config, "api_key", []) or []) if isinstance(getattr(new_config, "api_key", []), list) else []
    if old_url != getattr(new_config, "base_url", "") or old_model != getattr(new_config, "model_name", "") or old_keys != new_keys:
        LLM.reset_api_state()
    _apply_global_settings(new_config)
    _update_namespace_in_place(config_obj, new_config)
    llm.apply_runtime_config(config_obj)

# ä¸€äº›åˆå§‹åŒ–æ­¥éª¤
def load_config() -> tuple[LLM, NER, FileManager, SimpleNamespace, str]:
    with LogHelper.status("æ­£åœ¨åˆå§‹åŒ– [green] BookTerm Gacha [/] å¼•æ“ ..."):
        config, version = _load_config_namespace()
        _apply_global_settings(config)
        LLM.reset_api_state()

        # åˆå§‹åŒ– LLM å¯¹è±¡
        llm = LLM(config)
        llm.load_prompt()
        llm.load_llm_config()
        llm.set_request_limiter()

        # åˆå§‹åŒ– NER å¯¹è±¡
        ner = NER()
        ner.load_blacklist()
        # è®¾ç½® NER ç›®æ ‡å®ä½“ç±»å‹ï¼ˆä»é…ç½®åŠ è½½ï¼‰
        ner_target_types = getattr(config, 'ner_target_types', ["PER", "LOC"])
        ner.set_target_types(ner_target_types)

        # åˆå§‹åŒ– FileManager å¯¹è±¡ï¼ˆä¼ å…¥ç®€ç¹è½¬æ¢é…ç½®ï¼‰
        traditional_chinese_enable = getattr(config, 'traditional_chinese_enable', False)
        file_manager = FileManager(
            traditional_chinese_enable=traditional_chinese_enable
        )
        
        # æ‰“å°é…ç½®çŠ¶æ€
        LogHelper.info(f"ç½®ä¿¡åº¦é˜ˆå€¼: {SCORE_THRESHOLD}")
        LogHelper.info(f"æœ¯è¯­æœ€å¤§é•¿åº¦: {MAX_DISPLAY_LENGTH}")
        LogHelper.info(f"ä¸Šä¸‹æ–‡é‡‡æ ·æ•°: {Word.MAX_CONTEXT_SAMPLES}")
        LogHelper.info(f"æ¯æ ·æœ¬Tokenæ•°: {Word.TOKENS_PER_SAMPLE}")
        LogHelper.info(f"ä»»åŠ¡è¶…æ—¶é˜ˆå€¼: {LLM.TASK_TIMEOUT_THRESHOLD}s")
        LogHelper.info(f"NERç›®æ ‡ç±»å‹: {', '.join(ner_target_types)}")
        if traditional_chinese_enable:
            LogHelper.info("ç¹ä½“ä¸­æ–‡è¾“å‡ºå·²å¯ç”¨ ...")

    return llm, ner, file_manager, config, version

# ç¡®ä¿ç¨‹åºå‡ºé”™æ—¶å¯ä»¥æ•æ‰åˆ°é”™è¯¯æ—¥å¿—
async def main() -> None:
    try:
        parser = argparse.ArgumentParser(add_help=False)
        parser.add_argument("--no-status-writer", action="store_true")
        parser.add_argument("--no-ipc", action="store_true")
        args, _ = parser.parse_known_args()

        # æ³¨å†Œå…¨å±€å¼‚å¸¸è¿½è¸ªå™¨
        install()

        # åŠ è½½é…ç½®
        llm, ner, file_manager, config, version = load_config()
        writer = None if args.no_status_writer else _start_runtime_status_writer(llm)

        ipc_server = None
        if not args.no_ipc and bool(getattr(config, "ipc_enable", True)):
            from module.IpcServer import IpcServer
            from module.IpcProtocol import IpcResponse, sanitize_updates
            from module.ConfigStore import load_raw, save_raw, set_value, get_value, platform_summary

            ipc_lock = threading.Lock()

            def dispatch(method: str, params: dict, req_id: str) -> IpcResponse:
                rid = str(req_id or "req")
                try:
                    with ipc_lock:
                        if method == "get_status":
                            return IpcResponse(id=rid, ok=True, result=llm.get_runtime_status())
                        if method == "reload_platform":
                            _hot_reload_config(llm, config)
                            return IpcResponse(id=rid, ok=True, result={"status": llm.get_runtime_status()})
                        if method == "get_config":
                            path, raw = load_raw()
                            name, pid, key_count = platform_summary(raw)
                            result = {
                                "config_path": path,
                                "activate_platform": pid,
                                "platform_name": name,
                                "platform_key_count": key_count,
                                "multi_key_default_enable": bool(get_value(raw, "multi_key_default_enable", True)),
                                "multi_key_default_per_key_rpm": float(get_value(raw, "multi_key_default_per_key_rpm", 1) or 1),
                                "api_key_blacklist_ttl_seconds": int(get_value(raw, "api_key_blacklist_ttl_seconds", 3600) or 3600),
                                "max_concurrent_requests": int(get_value(raw, "max_concurrent_requests", 0) or 0),
                                "request_frequency_threshold": float(get_value(raw, "request_frequency_threshold", 1) or 1),
                                "ipc_host": str(getattr(config, "ipc_host", "127.0.0.1")),
                                "ipc_port": int(getattr(config, "ipc_port", 8765)),
                            }
                            return IpcResponse(id=rid, ok=True, result=result)
                        if method == "set_config":
                            updates = sanitize_updates(params.get("updates"))
                            path, raw = load_raw()
                            for k, v in updates.items():
                                set_value(raw, k, v)
                            save_raw(path, raw)
                            _hot_reload_config(llm, config)
                            return IpcResponse(id=rid, ok=True, result={"status": llm.get_runtime_status()})
                        return IpcResponse(id=rid, ok=False, error="unknown_method")
                except Exception as e:
                    return IpcResponse(id=rid, ok=False, error=str(e))

            host = str(getattr(config, "ipc_host", "127.0.0.1") or "127.0.0.1")
            port = int(getattr(config, "ipc_port", 8765) or 8765)
            ipc_server = IpcServer(host=host, port=port, dispatch=dispatch)
            ipc_server.start()

            def publish_loop() -> None:
                while True:
                    try:
                        with ipc_lock:
                            data = llm.get_runtime_status()
                        ipc_server.publish("status", data)
                    except Exception:
                        pass
                    time.sleep(0.25)

            threading.Thread(target=publish_loop, daemon=True).start()

        # å¼€å§‹å¤„ç†
        await begin(llm, ner, file_manager, config, version)
    except EOFError:
        LogHelper.error("EOFError - ç¨‹åºå³å°†é€€å‡º ...")
    except KeyboardInterrupt:
        LogHelper.error("KeyboardInterrupt - ç¨‹åºå³å°†é€€å‡º ...")
    except Exception as e:
        LogHelper.error(f"{LogHelper.get_trackback(e)}")
        LogHelper.print()
        LogHelper.error("å‡ºç°ä¸¥é‡é”™è¯¯ï¼Œç¨‹åºå³å°†é€€å‡ºï¼Œé”™è¯¯ä¿¡æ¯å·²ä¿å­˜è‡³æ—¥å¿—æ–‡ä»¶ ...")
        LogHelper.print()
        os.system("pause")

# å…¥å£å‡½æ•°
if __name__ == "__main__":
    asyncio.run(main())
