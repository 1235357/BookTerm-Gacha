"""
BookTerm Gacha - Environment Checker Module
============================================

This module provides automatic environment detection, validation, and repair
for the BookTerm Gacha application. It ensures all required dependencies
are installed with proper CUDA/GPU support.

Features:
    - Python version validation
    - Package dependency checking
    - CUDA/GPU detection and PyTorch CUDA support verification
    - Automatic package installation with fallback mirrors
    - Smart PyTorch reinstallation for CUDA support

Usage:
    from module.EnvChecker import EnvChecker
    
    checker = EnvChecker()
    if not checker.check_and_repair():
        sys.exit(1)

Based on KeywordGacha v0.13.1 by neavo
https://github.com/neavo/KeywordGacha
"""

import os
import sys
import subprocess
import importlib
import platform
from typing import Optional, Tuple, List, Dict
from dataclasses import dataclass, field

# Rich å¯èƒ½è¿˜æ²¡å®‰è£…ï¼Œæ‰€ä»¥å…ˆå°è¯•å¯¼å…¥ï¼Œå¤±è´¥åˆ™ç”¨ç®€å•æ‰“å°
try:
    from rich.console import Console
    from rich.table import Table
    from rich import box
    RICH_AVAILABLE = True
    _console = Console()
except ImportError:
    RICH_AVAILABLE = False
    _console = None


@dataclass
class PackageInfo:
    """åŒ…ä¿¡æ¯"""
    name: str                      # pip åŒ…å
    import_name: str = ""          # import æ—¶çš„æ¨¡å—åï¼ˆå¦‚æœä¸åŒï¼‰
    required: bool = True          # æ˜¯å¦å¿…éœ€
    min_version: str = ""          # æœ€ä½ç‰ˆæœ¬è¦æ±‚
    
    def __post_init__(self):
        if not self.import_name:
            self.import_name = self.name.replace("-", "_")


class EnvChecker:
    """ç¯å¢ƒæ£€æŸ¥å’Œè‡ªåŠ¨ä¿®å¤å™¨"""
    
    # Python æœ€ä½ç‰ˆæœ¬è¦æ±‚
    MIN_PYTHON_VERSION = (3, 10)
    
    # å›½å†…é•œåƒæºåˆ—è¡¨ï¼ˆæŒ‰ä¼˜å…ˆçº§æ’åºï¼‰
    MIRROR_SOURCES = [
        ("æ¸…åå¤§å­¦", "https://pypi.tuna.tsinghua.edu.cn/simple"),
        ("é˜¿é‡Œäº‘", "https://mirrors.aliyun.com/pypi/simple"),
        ("åä¸ºäº‘", "https://repo.huaweicloud.com/repository/pypi/simple"),
        ("è±†ç“£", "https://pypi.douban.com/simple"),
    ]
    
    # PyTorch CUDA é•œåƒæº
    PYTORCH_CUDA_SOURCES = [
        ("æ¸…åé•œåƒ", "https://mirrors.tuna.tsinghua.edu.cn/pytorch-wheels"),
        ("å®˜æ–¹æº", "https://download.pytorch.org/whl"),
    ]
    
    # æ ¸å¿ƒä¾èµ–åŒ…åˆ—è¡¨
    CORE_PACKAGES: List[PackageInfo] = [
        # Rich å¿…é¡»æœ€å…ˆå®‰è£…ï¼ˆç”¨äºç¾åŒ–è¾“å‡ºï¼‰
        PackageInfo("rich", "rich", True),
        PackageInfo("loguru", "loguru", True),
        
        # Transformers / NER
        PackageInfo("transformers", "transformers", True),
        
        # LLM API
        PackageInfo("openai", "openai", True),
        PackageInfo("aiolimiter", "aiolimiter", True),
        
        # æ–‡æœ¬å¤„ç†
        PackageInfo("tiktoken", "tiktoken", True),
        PackageInfo("pykakasi", "pykakasi", True),
        PackageInfo("sudachipy", "sudachipy", True),
        PackageInfo("sudachidict-core", "sudachidict_core", True),
        PackageInfo("pecab", "pecab", False),  # éŸ©è¯­ï¼Œéå¿…éœ€
        PackageInfo("opencc-python-reimplemented", "opencc", True),
        
        # æ–‡ä»¶æ ¼å¼
        PackageInfo("ebooklib", "ebooklib", True),
        PackageInfo("openpyxl", "openpyxl", True),
        PackageInfo("lxml", "lxml", True),
        PackageInfo("beautifulsoup4", "bs4", True),
        
        # å·¥å…·
        PackageInfo("json-repair", "json_repair", True),
    ]
    
    def __init__(self):
        self.issues: List[str] = []
        self.fixes_applied: List[str] = []
        self.cuda_version: Optional[str] = None
        self.gpu_name: Optional[str] = None
        self.pytorch_cuda_available: bool = False
        self.working_mirror: Optional[str] = None
    
    # ==================== æ—¥å¿—è¾“å‡º ====================
    
    def _print(self, message: str, style: str = "") -> None:
        """æ‰“å°æ¶ˆæ¯ï¼ˆå…¼å®¹ Rich ä¸å¯ç”¨çš„æƒ…å†µï¼‰"""
        if RICH_AVAILABLE and _console:
            if style:
                _console.print(f"[{style}]{message}[/{style}]")
            else:
                _console.print(message)
        else:
            # ç§»é™¤ Rich æ ‡è®°
            import re
            clean_msg = re.sub(r'\[/?[^\]]+\]', '', message)
            print(clean_msg)
    
    def _print_header(self, title: str) -> None:
        """æ‰“å°æ ‡é¢˜"""
        if RICH_AVAILABLE and _console:
            _console.print()
            _console.rule(f"[bold cyan]{title}[/bold cyan]", style="cyan")
            _console.print()
        else:
            print(f"\n{'='*60}")
            print(f"  {title}")
            print(f"{'='*60}\n")
    
    def _print_status(self, item: str, status: str, ok: bool) -> None:
        """æ‰“å°çŠ¶æ€è¡Œ"""
        if ok:
            icon = "âœ“"
            color = "green"
        else:
            icon = "âœ—"
            color = "red"
        
        if RICH_AVAILABLE and _console:
            _console.print(f"  [{color}]{icon}[/{color}] {item}: [{color}]{status}[/{color}]")
        else:
            print(f"  {icon} {item}: {status}")
    
    def _print_info(self, message: str) -> None:
        """æ‰“å°ä¿¡æ¯"""
        if RICH_AVAILABLE and _console:
            _console.print(f"  [dim]â„¹[/dim] {message}")
        else:
            print(f"  â„¹ {message}")
    
    def _print_warning(self, message: str) -> None:
        """æ‰“å°è­¦å‘Š"""
        if RICH_AVAILABLE and _console:
            _console.print(f"  [yellow]âš [/yellow] {message}")
        else:
            print(f"  âš  {message}")
    
    def _print_error(self, message: str) -> None:
        """æ‰“å°é”™è¯¯"""
        if RICH_AVAILABLE and _console:
            _console.print(f"  [red]âœ—[/red] {message}")
        else:
            print(f"  âœ— {message}")
    
    def _print_success(self, message: str) -> None:
        """æ‰“å°æˆåŠŸ"""
        if RICH_AVAILABLE and _console:
            _console.print(f"  [green]âœ“[/green] {message}")
        else:
            print(f"  âœ“ {message}")
    
    # ==================== ç¯å¢ƒæ£€æµ‹ ====================
    
    def check_python_version(self) -> bool:
        """æ£€æŸ¥ Python ç‰ˆæœ¬"""
        current = sys.version_info[:2]
        required = self.MIN_PYTHON_VERSION
        
        ok = current >= required
        status = f"{current[0]}.{current[1]}" + (f" (éœ€è¦ >= {required[0]}.{required[1]})" if not ok else "")
        self._print_status("Python ç‰ˆæœ¬", status, ok)
        
        if not ok:
            self.issues.append(f"Python ç‰ˆæœ¬è¿‡ä½: {current[0]}.{current[1]}ï¼Œéœ€è¦ >= {required[0]}.{required[1]}")
        
        return ok
    
    def check_cuda_environment(self) -> Tuple[bool, Optional[str], Optional[str]]:
        """
        æ£€æµ‹ CUDA ç¯å¢ƒ
        
        Returns:
            (cuda_available, cuda_version, gpu_name)
        """
        cuda_available = False
        cuda_version = None
        gpu_name = None
        
        # æ–¹æ³•1: å°è¯•è¿è¡Œ nvidia-smi
        try:
            result = subprocess.run(
                ["nvidia-smi", "--query-gpu=name,driver_version", "--format=csv,noheader,nounits"],
                capture_output=True,
                text=True,
                timeout=10,
                creationflags=subprocess.CREATE_NO_WINDOW if platform.system() == "Windows" else 0
            )
            if result.returncode == 0 and result.stdout.strip():
                parts = result.stdout.strip().split(",")
                if len(parts) >= 1:
                    gpu_name = parts[0].strip()
                cuda_available = True
        except (FileNotFoundError, subprocess.TimeoutExpired, Exception):
            pass
        
        # æ–¹æ³•2: è·å– CUDA ç‰ˆæœ¬
        if cuda_available:
            try:
                result = subprocess.run(
                    ["nvidia-smi", "--query-gpu=driver_version", "--format=csv,noheader"],
                    capture_output=True,
                    text=True,
                    timeout=10,
                    creationflags=subprocess.CREATE_NO_WINDOW if platform.system() == "Windows" else 0
                )
                if result.returncode == 0:
                    # ä»é©±åŠ¨ç‰ˆæœ¬æ¨æ–­ CUDA ç‰ˆæœ¬
                    driver_version = result.stdout.strip()
                    cuda_version = self._driver_to_cuda_version(driver_version)
            except Exception:
                pass
        
        # å­˜å‚¨ç»“æœ
        self.cuda_version = cuda_version
        self.gpu_name = gpu_name
        
        # æ‰“å°çŠ¶æ€
        if cuda_available:
            self._print_status("NVIDIA GPU", f"{gpu_name}", True)
            self._print_status("CUDA æ”¯æŒ", f"é©±åŠ¨æ”¯æŒ CUDA {cuda_version or 'æœªçŸ¥ç‰ˆæœ¬'}", True)
        else:
            self._print_status("NVIDIA GPU", "æœªæ£€æµ‹åˆ°", False)
            self._print_warning("â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—")
            self._print_warning("â•‘  æœªæ£€æµ‹åˆ° NVIDIA GPUï¼Œç¨‹åºå°†ä½¿ç”¨ CPU æ¨¡å¼è¿è¡Œ               â•‘")
            self._print_warning("â•‘  NER å®ä½“è¯†åˆ«é€Ÿåº¦ä¼šæ˜¾è‘—é™ä½ï¼ˆçº¦ 10-50 å€ï¼‰                  â•‘")
            self._print_warning("â•‘                                                            â•‘")
            self._print_warning("â•‘  å¦‚æœæ‚¨æœ‰ NVIDIA æ˜¾å¡ï¼Œè¯·æ£€æŸ¥ï¼š                            â•‘")
            self._print_warning("â•‘  1. æ˜¯å¦å·²å®‰è£… NVIDIA æ˜¾å¡é©±åŠ¨                             â•‘")
            self._print_warning("â•‘  2. é©±åŠ¨ç‰ˆæœ¬æ˜¯å¦è¿‡æ—§ï¼ˆå»ºè®® >= 470ï¼‰                        â•‘")
            self._print_warning("â•‘  3. ä¸‹è½½é©±åŠ¨: https://www.nvidia.cn/drivers/               â•‘")
            self._print_warning("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
        
        return cuda_available, cuda_version, gpu_name
    
    def _driver_to_cuda_version(self, driver_version: str) -> Optional[str]:
        """æ ¹æ®é©±åŠ¨ç‰ˆæœ¬æ¨æ–­æ”¯æŒçš„ CUDA ç‰ˆæœ¬"""
        try:
            major = int(driver_version.split(".")[0])
            # NVIDIA é©±åŠ¨ç‰ˆæœ¬ä¸ CUDA ç‰ˆæœ¬å¯¹åº”å…³ç³»ï¼ˆè¿‘ä¼¼ï¼‰
            if major >= 560:
                return "12.6"
            elif major >= 550:
                return "12.4"
            elif major >= 530:
                return "12.1"
            elif major >= 520:
                return "11.8"
            elif major >= 510:
                return "11.6"
            elif major >= 470:
                return "11.4"
            else:
                return "11.0"
        except Exception:
            return None
    
    def check_pytorch(self) -> Tuple[bool, bool]:
        """
        æ£€æŸ¥ PyTorch å®‰è£…çŠ¶æ€
        
        Returns:
            (installed, cuda_enabled)
        """
        installed = False
        cuda_enabled = False
        
        try:
            import torch
            installed = True
            cuda_enabled = torch.cuda.is_available()
            
            version = torch.__version__
            if cuda_enabled:
                device_name = torch.cuda.get_device_name(0)
                self._print_status("PyTorch", f"{version} (CUDA å·²å¯ç”¨)", True)
                self._print_info(f"GPU è®¾å¤‡: {device_name}")
                self.pytorch_cuda_available = True
            else:
                self._print_status("PyTorch", f"{version} (ä»… CPU)", False)
                if self.cuda_version:
                    self._print_warning("æ£€æµ‹åˆ° GPU ä½† PyTorch æœªå¯ç”¨ CUDAï¼Œå»ºè®®é‡æ–°å®‰è£…")
        except ImportError:
            self._print_status("PyTorch", "æœªå®‰è£…", False)
            self.issues.append("PyTorch æœªå®‰è£…")
        
        return installed, cuda_enabled
    
    def check_package(self, pkg: PackageInfo) -> bool:
        """æ£€æŸ¥å•ä¸ªåŒ…æ˜¯å¦å·²å®‰è£…"""
        try:
            importlib.import_module(pkg.import_name)
            return True
        except ImportError:
            return False
    
    def check_all_packages(self) -> Dict[str, bool]:
        """æ£€æŸ¥æ‰€æœ‰ä¾èµ–åŒ…"""
        results = {}
        missing_required = []
        missing_optional = []
        
        for pkg in self.CORE_PACKAGES:
            installed = self.check_package(pkg)
            results[pkg.name] = installed
            
            if not installed:
                if pkg.required:
                    missing_required.append(pkg.name)
                else:
                    missing_optional.append(pkg.name)
        
        # æ‰“å°æ‘˜è¦
        total = len(self.CORE_PACKAGES)
        installed_count = sum(1 for v in results.values() if v)
        
        if installed_count == total:
            self._print_status("ä¾èµ–åŒ…", f"å…¨éƒ¨å·²å®‰è£… ({installed_count}/{total})", True)
        else:
            self._print_status("ä¾èµ–åŒ…", f"å·²å®‰è£… {installed_count}/{total}", False)
            if missing_required:
                self._print_warning(f"ç¼ºå°‘å¿…éœ€åŒ…: {', '.join(missing_required)}")
                self.issues.append(f"ç¼ºå°‘å¿…éœ€åŒ…: {', '.join(missing_required)}")
            if missing_optional:
                self._print_info(f"ç¼ºå°‘å¯é€‰åŒ…: {', '.join(missing_optional)}")
        
        return results
    
    # ==================== è‡ªåŠ¨ä¿®å¤ ====================
    
    def _find_working_mirror(self) -> Optional[str]:
        """æµ‹è¯•å¹¶æ‰¾åˆ°å¯ç”¨çš„é•œåƒæº"""
        if self.working_mirror:
            return self.working_mirror
        
        self._print_info("æ­£åœ¨æµ‹è¯•é•œåƒæºè¿æ¥...")
        
        for name, url in self.MIRROR_SOURCES:
            try:
                result = subprocess.run(
                    [sys.executable, "-m", "pip", "install", "--dry-run", "-i", url, "pip"],
                    capture_output=True,
                    text=True,
                    timeout=15,
                    creationflags=subprocess.CREATE_NO_WINDOW if platform.system() == "Windows" else 0
                )
                if result.returncode == 0 or "already satisfied" in result.stdout.lower():
                    self._print_success(f"ä½¿ç”¨é•œåƒæº: {name} ({url})")
                    self.working_mirror = url
                    return url
            except Exception:
                continue
        
        self._print_warning("æ‰€æœ‰é•œåƒæºå‡ä¸å¯ç”¨ï¼Œå°è¯•ä½¿ç”¨é»˜è®¤æº")
        return None
    
    def _pip_install(self, packages: List[str], extra_args: List[str] = None) -> bool:
        """ä½¿ç”¨ pip å®‰è£…åŒ…"""
        if not packages:
            return True
        
        mirror = self._find_working_mirror()
        
        cmd = [sys.executable, "-m", "pip", "install", "--upgrade"]
        if mirror:
            cmd.extend(["-i", mirror, "--trusted-host", mirror.split("//")[1].split("/")[0]])
        if extra_args:
            cmd.extend(extra_args)
        cmd.extend(packages)
        
        self._print_info(f"æ­£åœ¨å®‰è£…: {', '.join(packages)}")
        
        try:
            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                timeout=600,  # 10åˆ†é’Ÿè¶…æ—¶
                creationflags=subprocess.CREATE_NO_WINDOW if platform.system() == "Windows" else 0
            )
            
            if result.returncode == 0:
                self._print_success(f"å®‰è£…æˆåŠŸ: {', '.join(packages)}")
                return True
            else:
                self._print_error(f"å®‰è£…å¤±è´¥: {result.stderr[:200] if result.stderr else 'æœªçŸ¥é”™è¯¯'}")
                return False
        except subprocess.TimeoutExpired:
            self._print_error("å®‰è£…è¶…æ—¶ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥")
            return False
        except Exception as e:
            self._print_error(f"å®‰è£…å‡ºé”™: {e}")
            return False
    
    def install_pytorch_cuda(self) -> bool:
        """å®‰è£…æ”¯æŒ CUDA çš„ PyTorch"""
        if not self.cuda_version:
            self._print_warning("æœªæ£€æµ‹åˆ° CUDAï¼Œå°†å®‰è£… CPU ç‰ˆæœ¬ PyTorch")
            return self._pip_install(["torch", "torchvision", "torchaudio"])
        
        # ç¡®å®š CUDA ç‰ˆæœ¬å¯¹åº”çš„ PyTorch wheel URL
        cuda_map = {
            "12.6": "cu126",
            "12.4": "cu124", 
            "12.1": "cu121",
            "11.8": "cu118",
        }
        
        # æ‰¾åˆ°æœ€æ¥è¿‘çš„ CUDA ç‰ˆæœ¬
        cuda_tag = None
        try:
            cuda_major_minor = ".".join(self.cuda_version.split(".")[:2])
            if cuda_major_minor in cuda_map:
                cuda_tag = cuda_map[cuda_major_minor]
            else:
                # å°è¯•æ‰¾åˆ°æœ€æ¥è¿‘çš„ç‰ˆæœ¬
                cuda_float = float(cuda_major_minor)
                for ver, tag in sorted(cuda_map.items(), key=lambda x: float(x[0]), reverse=True):
                    if cuda_float >= float(ver):
                        cuda_tag = tag
                        break
        except Exception:
            cuda_tag = "cu121"  # é»˜è®¤ä½¿ç”¨ CUDA 12.1
        
        if not cuda_tag:
            cuda_tag = "cu121"
        
        self._print_info(f"å°†å®‰è£… PyTorch with CUDA {cuda_tag}")
        
        # å…ˆå¸è½½ç°æœ‰çš„ PyTorch
        self._print_info("æ­£åœ¨å¸è½½ç°æœ‰ PyTorch...")
        subprocess.run(
            [sys.executable, "-m", "pip", "uninstall", "-y", "torch", "torchvision", "torchaudio"],
            capture_output=True,
            creationflags=subprocess.CREATE_NO_WINDOW if platform.system() == "Windows" else 0
        )
        
        # å°è¯•ä»ä¸åŒæºå®‰è£…
        for source_name, source_url in self.PYTORCH_CUDA_SOURCES:
            self._print_info(f"å°è¯•ä» {source_name} å®‰è£… PyTorch CUDA...")
            
            index_url = f"{source_url}/{cuda_tag}"
            
            cmd = [
                sys.executable, "-m", "pip", "install",
                "torch", "torchvision", "torchaudio",
                "--index-url", index_url
            ]
            
            try:
                result = subprocess.run(
                    cmd,
                    capture_output=True,
                    text=True,
                    timeout=1200,  # 20åˆ†é’Ÿè¶…æ—¶ï¼ˆPyTorch å¾ˆå¤§ï¼‰
                    creationflags=subprocess.CREATE_NO_WINDOW if platform.system() == "Windows" else 0
                )
                
                if result.returncode == 0:
                    # éªŒè¯å®‰è£…
                    try:
                        # å¼ºåˆ¶é‡æ–°åŠ è½½ torch
                        if "torch" in sys.modules:
                            del sys.modules["torch"]
                        import torch
                        if torch.cuda.is_available():
                            self._print_success(f"PyTorch CUDA å®‰è£…æˆåŠŸï¼GPU: {torch.cuda.get_device_name(0)}")
                            self.pytorch_cuda_available = True
                            return True
                        else:
                            self._print_warning("PyTorch å·²å®‰è£…ä½† CUDA ä¸å¯ç”¨")
                    except Exception as e:
                        self._print_warning(f"éªŒè¯å¤±è´¥: {e}")
                else:
                    self._print_warning(f"ä» {source_name} å®‰è£…å¤±è´¥ï¼Œå°è¯•ä¸‹ä¸€ä¸ªæº...")
            except subprocess.TimeoutExpired:
                self._print_warning(f"ä» {source_name} å®‰è£…è¶…æ—¶ï¼Œå°è¯•ä¸‹ä¸€ä¸ªæº...")
            except Exception as e:
                self._print_warning(f"å®‰è£…å‡ºé”™: {e}")
        
        # æ‰€æœ‰æºéƒ½å¤±è´¥ï¼Œå®‰è£… CPU ç‰ˆæœ¬ä½œä¸ºåå¤‡
        self._print_warning("æ— æ³•å®‰è£… CUDA ç‰ˆæœ¬ï¼Œå°†å®‰è£… CPU ç‰ˆæœ¬")
        return self._pip_install(["torch", "torchvision", "torchaudio"])
    
    def install_missing_packages(self, missing: List[str]) -> bool:
        """å®‰è£…ç¼ºå¤±çš„åŒ…"""
        if not missing:
            return True
        
        # æ’é™¤ PyTorch ç›¸å…³åŒ…ï¼ˆå•ç‹¬å¤„ç†ï¼‰
        pytorch_packages = {"torch", "torchvision", "torchaudio"}
        other_packages = [p for p in missing if p not in pytorch_packages]
        
        success = True
        
        # å®‰è£…å…¶ä»–åŒ…
        if other_packages:
            if not self._pip_install(other_packages):
                success = False
        
        return success
    
    # ==================== ä¸»å…¥å£ ====================
    
    def check_and_repair(self, auto_repair: bool = True) -> bool:
        """
        æ£€æŸ¥ç¯å¢ƒå¹¶è‡ªåŠ¨ä¿®å¤
        
        Args:
            auto_repair: æ˜¯å¦è‡ªåŠ¨ä¿®å¤é—®é¢˜
            
        Returns:
            ç¯å¢ƒæ˜¯å¦å°±ç»ª
        """
        self._print_header("ğŸ” ç¯å¢ƒæ£€æµ‹")
        
        # 1. æ£€æŸ¥ Python ç‰ˆæœ¬
        python_ok = self.check_python_version()
        if not python_ok:
            self._print_error("Python ç‰ˆæœ¬è¿‡ä½ï¼Œè¯·å‡çº§åˆ° 3.10 æˆ–æ›´é«˜ç‰ˆæœ¬")
            return False
        
        # 2. æ£€æŸ¥ CUDA ç¯å¢ƒ
        cuda_available, cuda_version, gpu_name = self.check_cuda_environment()
        
        # 3. æ£€æŸ¥ PyTorch
        pytorch_installed, pytorch_cuda = self.check_pytorch()
        
        # 4. æ£€æŸ¥å…¶ä»–ä¾èµ–åŒ…
        package_status = self.check_all_packages()
        
        # æ”¶é›†éœ€è¦ä¿®å¤çš„é—®é¢˜
        need_pytorch_reinstall = cuda_available and pytorch_installed and not pytorch_cuda
        need_pytorch_install = not pytorch_installed
        missing_packages = [pkg.name for pkg in self.CORE_PACKAGES if not package_status.get(pkg.name, False)]
        
        # å¦‚æœä¸€åˆ‡æ­£å¸¸
        if not need_pytorch_reinstall and not need_pytorch_install and not missing_packages:
            self._print_header("âœ… ç¯å¢ƒæ£€æµ‹å®Œæˆ")
            self._print_success("æ‰€æœ‰ä¾èµ–å·²å°±ç»ªï¼Œç¯å¢ƒæ­£å¸¸ï¼")
            if cuda_available and pytorch_cuda:
                self._print_success(f"GPU åŠ é€Ÿå·²å¯ç”¨: {gpu_name}")
            return True
        
        # éœ€è¦ä¿®å¤
        if not auto_repair:
            self._print_header("âš ï¸ ç¯å¢ƒé—®é¢˜")
            if need_pytorch_install:
                self._print_error("PyTorch æœªå®‰è£…")
            if need_pytorch_reinstall:
                self._print_warning("PyTorch æœªå¯ç”¨ CUDAï¼Œå»ºè®®é‡æ–°å®‰è£…")
            if missing_packages:
                self._print_error(f"ç¼ºå°‘ä¾èµ–åŒ…: {', '.join(missing_packages)}")
            return False
        
        # è‡ªåŠ¨ä¿®å¤
        self._print_header("ğŸ”§ è‡ªåŠ¨ä¿®å¤")
        
        # ä¿®å¤ PyTorch
        if need_pytorch_install or need_pytorch_reinstall:
            self._print_info("æ­£åœ¨ä¿®å¤ PyTorch å®‰è£…...")
            if not self.install_pytorch_cuda():
                self._print_warning("PyTorch å®‰è£…å¯èƒ½ä¸å®Œæ•´ï¼Œä½†ç¨‹åºä»å¯è¿è¡Œï¼ˆä½¿ç”¨ CPUï¼‰")
        
        # ä¿®å¤å…¶ä»–åŒ…
        if missing_packages:
            self._print_info("æ­£åœ¨å®‰è£…ç¼ºå¤±çš„ä¾èµ–åŒ…...")
            if not self.install_missing_packages(missing_packages):
                self._print_error("éƒ¨åˆ†ä¾èµ–åŒ…å®‰è£…å¤±è´¥")
                return False
        
        # æœ€ç»ˆéªŒè¯
        self._print_header("ğŸ”„ é‡æ–°éªŒè¯")
        
        # é‡æ–°æ£€æŸ¥ PyTorch
        pytorch_installed, pytorch_cuda = self.check_pytorch()
        
        # é‡æ–°æ£€æŸ¥åŒ…
        final_missing = []
        for pkg in self.CORE_PACKAGES:
            if pkg.required and not self.check_package(pkg):
                final_missing.append(pkg.name)
        
        if final_missing:
            self._print_status("ä¾èµ–åŒ…", f"ä»ç¼ºå°‘: {', '.join(final_missing)}", False)
            return False
        
        self._print_header("âœ… ç¯å¢ƒä¿®å¤å®Œæˆ")
        self._print_success("æ‰€æœ‰ä¾èµ–å·²å°±ç»ªï¼")
        
        if pytorch_cuda:
            self._print_success(f"GPU åŠ é€Ÿå·²å¯ç”¨: {self.gpu_name or 'NVIDIA GPU'}")
        elif cuda_available:
            self._print_warning("GPU å¯ç”¨ä½† PyTorch CUDA æœªå¯ç”¨ï¼Œå°†ä½¿ç”¨ CPU æ¨¡å¼")
        else:
            self._print_info("å°†ä½¿ç”¨ CPU æ¨¡å¼è¿è¡Œ")
        
        return True
    
    def print_environment_summary(self) -> None:
        """æ‰“å°ç¯å¢ƒæ‘˜è¦ï¼ˆç”¨äºå¯åŠ¨æ—¶æ˜¾ç¤ºï¼‰"""
        if not RICH_AVAILABLE:
            return
        
        try:
            import torch
            pytorch_version = torch.__version__
            cuda_available = torch.cuda.is_available()
            device = torch.cuda.get_device_name(0) if cuda_available else "CPU"
        except ImportError:
            pytorch_version = "æœªå®‰è£…"
            cuda_available = False
            device = "N/A"
        
        table = Table(
            box=box.ROUNDED,
            title="[bold]è¿è¡Œç¯å¢ƒ[/bold]",
            title_style="cyan",
            expand=False,
        )
        table.add_column("é¡¹ç›®", style="dim")
        table.add_column("çŠ¶æ€", justify="right")
        
        table.add_row("Python", f"{sys.version_info.major}.{sys.version_info.minor}.{sys.version_info.micro}")
        table.add_row("PyTorch", pytorch_version)
        table.add_row("CUDA", "[green]å·²å¯ç”¨[/green]" if cuda_available else "[yellow]æœªå¯ç”¨[/yellow]")
        table.add_row("è®¾å¤‡", device)
        
        _console.print()
        _console.print(table)
        _console.print()


# ä¾¿æ·å‡½æ•°
def check_environment(auto_repair: bool = True) -> bool:
    """
    æ£€æŸ¥å¹¶ä¿®å¤è¿è¡Œç¯å¢ƒ
    
    Args:
        auto_repair: æ˜¯å¦è‡ªåŠ¨ä¿®å¤é—®é¢˜
        
    Returns:
        ç¯å¢ƒæ˜¯å¦å°±ç»ª
    """
    # æ£€æµ‹æ˜¯å¦åœ¨ PyInstaller æ‰“åŒ…ç¯å¢ƒä¸­è¿è¡Œ
    # å¦‚æœæ˜¯ï¼Œè·³è¿‡ç¯å¢ƒæ£€æŸ¥ï¼ˆä¾èµ–å·²ç»æ‰“åŒ…ï¼‰
    if getattr(sys, 'frozen', False):
        # åœ¨æ‰“åŒ…ç¯å¢ƒä¸­ï¼Œç®€å•æ‰“å°å¯åŠ¨ä¿¡æ¯
        print("=" * 60)
        print("  BookTerm Gacha - Starting...")
        print("=" * 60)
        return True
    
    checker = EnvChecker()
    return checker.check_and_repair(auto_repair)


if __name__ == "__main__":
    # ç›´æ¥è¿è¡Œæ—¶è¿›è¡Œç¯å¢ƒæ£€æŸ¥
    check_environment(auto_repair=True)
